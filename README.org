#+title: MNIST from scratch
#+description: Using cuda to fit MNIST

* Acknowledgements
This project is inspired by the YouTube series on GPU programming by [[https://www.youtube.com/playlist?list=PL5XwKDZZlwaY7t0M5OLprpkJUIrF8Lc9j][Simon Oz]]. Most of the kernels are based on the didactic examples he provides. Thank you Simon!

* Data
#+begin_src bash :noeval
curl -O https://pjreddie.com/media/files/mnist_train.csv
curl -O https://pjreddie.com/media/files/mnist_test.csv
#+end_src

* Main program
:PROPERTIES:
:header-args:C++: :tangle "src/main.cpp" :main no
:END:
** Imports
#+begin_src C++
// kernels from ./kenels/bw.cu and ./kernels/fw.cu
#include "../kernels/bw.cu"
#include "../kernels/fw.cu"

#include "helpers.cpp"

#include <chrono>
#include <fstream>
#include <iomanip>
#include <iostream> 
#include <curand.h>
#include <curand_kernel.h>
#include <cuda_runtime.h>
#include <cassert>
#include <string>

#define ASSERT(cond, msg, args...) assert((cond) || !fprintf(stderr, (msg "\n"), args))
#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }
#+end_src

** Start main
#+begin_src C++
int main(int argc, char** argv)
{
#+end_src
** Load the dataset
#+begin_src C++
  // Dataset sizes
  int testSetSize = 10000;   // Number of test examples
  int trainSetSize = 60000;  // Number of training examples

  // Input and output dimensions
  int inputFeatureSize = 784;  // 28x28 = 784 pixels per image
  int numClasses = 10;         // 10 possible digits (0-9)

  // Container arrays for the MNIST dataset
  // Shape: [numExamples x inputFeatureSize] for images (flattened 28x28 pixels)
  // Shape: [numExamples x numClasses] for labels (one-hot encoded)
  float* trainImages = new float[inputFeatureSize * trainSetSize]; 
  float* trainLabels = new float[numClasses * trainSetSize];
    
  float* testImages = new float[inputFeatureSize * testSetSize];
  float* testLabels = new float[numClasses * testSetSize];

  // Load MNIST dataset
  {
    Timer t("read mnist");
    read_mnist("./mnist_train.csv", trainSetSize, trainImages, trainLabels);
    read_mnist("./mnist_test.csv", testSetSize, testImages, testLabels);
  }

#+end_src
** Initialize memory
#+begin_src C++
  // Memory 
  float* deviceInput;    // Shape: [batchSize x inputFeatureSize]
  float* deviceLabels;   // Shape: [batchSize x numClasses]

  /// NETWORK
  // Layer 1
  int hiddenSize1 = 300;
  float* hiddenWeights1;  // Shape: [hiddenSize1 x inputFeatureSize]
  float* hiddenBiases1;   // Shape: [hiddenSize1]
  float* hiddenGradients1; // Shape: [hiddenSize1 x batchSize]

  // layer 2
  int hiddenSize2 = 100;
  float* hiddenWeights2;  // Shape: [hiddenSize2 x hiddenSize1]
  float* hiddenBiases2;   // Shape: [hiddenSize2]
  float* hiddenGradients2; // Shape: [hiddenSize2 x batchSize]

  // Output layer: 10 neurons
  int outputSize = 10;
  float* outputWeights;  // Shape: [outputSize x hiddenSize2]
  float* outputBiases;   // Shape: [outputSize]
  float* outputGradients; // Shape: [outputSize x batchSize]

  // Training hyperparameters
  int BLOCK_SIZE = 16;     // Size of CUDA thread blocks
  int BATCH_SIZE = 16;     // Number of examples processed in parallel
  int EPOCHS = 10;         // Number of complete passes through the training set
  float LEARNING_RATE = 0.003f;  // Step size for gradient descent updates

  
  dim3 dimGrid;
  dim3 dimBlock;

  float* hostOutputs = new float[BATCH_SIZE * outputSize];
  float* hostLosses = new float[BATCH_SIZE];

  // Layer activation storage
  // For each layer, we need to store:
  // - preActivations (x): the weighted sum before activation function
  // - activations (a): the output after applying the activation function

  // Hidden layer 1 intermediates
  float* preActivationsLayer1;  // Shape: [hiddenSize1 x batchSize]
  float* activationsLayer1;     // Shape: [hiddenSize1 x batchSize]
    
  // Hidden layer 2 intermediates
  float* preActivationsLayer2;  // Shape: [hiddenSize2 x batchSize]
  float* activationsLayer2;     // Shape: [hiddenSize2 x batchSize]
    
  // Output layer intermediates
  float* preActivationsOutput;  // Shape: [outputSize x batchSize]
  float* activationsOutput;     // Shape: [outputSize x batchSize]

  // Loss values for the batch
  float* deviceLosses;  // Shape: [batchSize]

#+end_src
** Allocate in the gpu
#+begin_src C++
  // Allocate and initialize GPU memory
  {
    Timer init("initialization");
	
    // Allocate memory for input data
    gpuErrchk(cudaMalloc((void**) &deviceInput, inputFeatureSize * BATCH_SIZE * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &deviceLabels, numClasses * BATCH_SIZE * sizeof(float)));

    // Allocate and initialize first hidden layer
    gpuErrchk(cudaMalloc((void**) &hiddenWeights1, hiddenSize1 * inputFeatureSize * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &hiddenBiases1, hiddenSize1 * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &hiddenGradients1, hiddenSize1 * BATCH_SIZE * sizeof(float)));
    initLayer(hiddenWeights1, hiddenBiases1, hiddenSize1, inputFeatureSize, BLOCK_SIZE);

    // Allocate and initialize second hidden layer
    gpuErrchk(cudaMalloc((void**) &hiddenWeights2, hiddenSize2 * hiddenSize1 * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &hiddenBiases2, hiddenSize2 * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &hiddenGradients2, hiddenSize2 * BATCH_SIZE * sizeof(float)));
    initLayer(hiddenWeights2, hiddenBiases2, hiddenSize2, hiddenSize1, BLOCK_SIZE);

    // Allocate and initialize output layer
    gpuErrchk(cudaMalloc((void**) &outputWeights, outputSize * hiddenSize2 * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &outputBiases, outputSize * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &outputGradients, outputSize * BATCH_SIZE * sizeof(float)));
    initLayer(outputWeights, outputBiases, outputSize, hiddenSize2, BLOCK_SIZE);

    // Allocate memory for layer activations
    gpuErrchk(cudaMalloc((void**) &preActivationsLayer1, hiddenSize1 * BATCH_SIZE * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &activationsLayer1, hiddenSize1 * BATCH_SIZE * sizeof(float)));

    gpuErrchk(cudaMalloc((void**) &preActivationsLayer2, hiddenSize2 * BATCH_SIZE * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &activationsLayer2, hiddenSize2 * BATCH_SIZE * sizeof(float)));

    gpuErrchk(cudaMalloc((void**) &preActivationsOutput, outputSize * BATCH_SIZE * sizeof(float)));
    gpuErrchk(cudaMalloc((void**) &activationsOutput, outputSize * BATCH_SIZE * sizeof(float)));

    gpuErrchk(cudaMalloc((void**) &deviceLosses, BATCH_SIZE * sizeof(float)));
  }
#+end_src
** Training LOOP Start
#+begin_src C++
  float totalTrainingTime = 0.0f;

  // Training loop
  for(int epoch = 0; epoch < EPOCHS; epoch++) {
    float cumulativeLoss = 0.0f;
    int correctPredictions = 0;
    int totalPredictions = 0;
    auto startTime = std::chrono::system_clock::now();

    // Process mini-batches
    for(int batch = 0; batch < trainSetSize / BATCH_SIZE; batch++) {
      totalPredictions += BATCH_SIZE;
      // Copy current batch to GPU
      gpuErrchk(cudaMemcpy(
			   deviceInput, 
			   &trainImages[batch * BATCH_SIZE * inputFeatureSize], 
			   BATCH_SIZE * inputFeatureSize * sizeof(float), 
			   cudaMemcpyHostToDevice
			   )); 
      
      gpuErrchk(cudaMemcpy(
			   deviceLabels, 
			   &trainLabels[batch * BATCH_SIZE * numClasses], 
			   BATCH_SIZE * numClasses * sizeof(float), 
			   cudaMemcpyHostToDevice
			   )); 
#+end_src
** Forward pass
#+begin_src C++
      // ========== FORWARD PASS ==========
	    
      // First hidden layer forward pass
      // 19 , 1
      dimGrid = dim3(ceil(hiddenSize1/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
	    
      forward<<<dimGrid, dimBlock>>>(
				     BATCH_SIZE, inputFeatureSize, hiddenSize1, 
				     deviceInput, hiddenWeights1, hiddenBiases1, preActivationsLayer1
				     );
      gpuErrchk(cudaPeekAtLastError());

      // Apply ReLU activation to first hidden layer
      relu<<<dimGrid, dimBlock>>>(
				  hiddenSize1, BATCH_SIZE, 
				  preActivationsLayer1, activationsLayer1
				  );
      gpuErrchk(cudaPeekAtLastError());

      // Second hidden layer forward pass
      // 100/16 = 7, (16/16)= 1  ===> 7,1
      dimGrid = dim3(ceil(hiddenSize2/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
	    
      forward<<<dimGrid, dimBlock>>>(
				     BATCH_SIZE, hiddenSize1, hiddenSize2, 
				     activationsLayer1, hiddenWeights2, hiddenBiases2, preActivationsLayer2
				     );
      gpuErrchk(cudaPeekAtLastError());

     
      // Apply ReLU activation to second hidden layer
      relu<<<dimGrid, dimBlock>>>(
				  hiddenSize2, BATCH_SIZE, 
				  preActivationsLayer2, activationsLayer2
				  );
      gpuErrchk(cudaPeekAtLastError());

      // Output layer forward pass
      dimGrid = dim3(ceil(outputSize/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
	    
      forward<<<dimGrid, dimBlock>>>(
				     BATCH_SIZE, hiddenSize2, outputSize, 
				     activationsLayer2, outputWeights, outputBiases, preActivationsOutput
				     );
      gpuErrchk(cudaPeekAtLastError());

      // Apply softmax activation to output layer
      softmax<<<dimGrid, dimBlock>>>(
				     outputSize, BATCH_SIZE, 
				     preActivationsOutput, activationsOutput
				     );
      gpuErrchk(cudaPeekAtLastError());
#+end_src
** Compute loss and evalutate
#+begin_src C++
      // Compute the loss
      dimGrid = dim3(ceil(outputSize/(float)BLOCK_SIZE), 1, 1);
      dimBlock = dim3(BLOCK_SIZE, 1, 1);
      cross_entropy<<<dimGrid, dimBlock>>>(
					   outputSize, BATCH_SIZE, 
					   activationsOutput, deviceLabels, deviceLosses
					   );

      gpuErrchk(cudaDeviceSynchronize());

      // Copy results back to host for evaluation
      gpuErrchk(cudaMemcpy(
			   hostOutputs, activationsOutput, 
			   BATCH_SIZE * outputSize * sizeof(float), 
			   cudaMemcpyDeviceToHost
			   ));
      gpuErrchk(cudaMemcpy(
			   hostLosses, deviceLosses, 
			   BATCH_SIZE * sizeof(float), 
			   cudaMemcpyDeviceToHost
			   ));

      // Evaluate predictions and calculate metrics
      for (int i = 0; i < BATCH_SIZE; i++) {
	float maxPredictedProb = 0.0f;
	float maxTrueProb = 0.0f;
	int predictedDigit = 0;
	int trueDigit = 0;
		
	// Find the predicted and true digits (highest probability)
	for (int j = 0; j < numClasses; j++) {
	  // Check prediction
	  if (hostOutputs[i * numClasses + j] > maxPredictedProb) {
	    maxPredictedProb = hostOutputs[i * numClasses + j];
	    predictedDigit = j;
	  }
		    
	  // Check ground truth
	  if (trainLabels[batch * BATCH_SIZE * numClasses + i * numClasses + j] > maxTrueProb) {
	    maxTrueProb = trainLabels[batch * BATCH_SIZE * numClasses + i * numClasses + j];
	    trueDigit = j;
	  }
	}
      }

#+end_src
** Backwards pass
#+begin_src C++
      // Backwards
      // We use the same variable to apply backprop on the inputs
      // first we apply backprop from the next layer to this layer before activation
      // then we apply the relu to backprop to pre activation. both are held in hiddenGradientsN variables
      // it is the gradients for the layer before activation

      // grads for output
      dimGrid = dim3(ceil(outputSize/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE, 1));
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);

      ce_back<<dimGrid, dimBlock>>(
				   outputSize, BATCH_SIZE,
				   activationsOutput, deviceLabels, outputGradients
				   );
      gpuErrchk(cudaPeekAtLastError());

      // backprop to second layer
      dimGrid = dim3(ceil(hiddenSize2/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE, 1));
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);

      // progate to the gradients before activation
      backward<<dimGrid, dimBlock>>(
				    BATCH_SIZE, outputSize, hiddenSize2,
				    outputWeights, outputBiases, outputGradients, hiddenGradients2
				    );
      gpuErrchk(cudaPeekAtLastError());

      // back prop through the relu
      relu_backwards<<<dimGrid, dimBlock>>>(
					    hiddenSize2, BATCH_SIZE, 
					    activationsLayer2, hiddenGradients2, hiddenGradients2
					    );

      // backprop to first layer
      dimGrid = dim3(ceil(hiddenSize1/(float)BLOCK_SIZE), ceil(BATCH_SIZE/(float)BLOCK_SIZE, 1));
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);

      // progate to the gradients before activation
      backward<<dimGrid, dimBlock>>(
				    BATCH_SIZE, hiddenSize2, hiddenSize1,
				    hiddenWeights2, hiddenBiases2, hiddenGradients2, hiddenGradients1
				    );
      gpuErrchk(cudaPeekAtLastError());

      // now through relu to pre act
      relu_backwards<<<dimGrid, dimBlock>>>(
					    hiddenSize1, BATCH_SIZE, 
					    activationsLayer1, hiddenGradients1, hiddenGradients1
					    );

#+end_src
** Update the weights (.backwards)
#+begin_src C++
      // Update of weights
      // all the hiddenGradtiensN contain the gradients of the inputs pre activation with respect to loss
      // outsize, hidsize2 = shape of weights
      // we update the weights of the output layer
      // we use the activations of the previous layer to update this
      dimGrid = dim3(ceil(outputSize/(float)BLOCK_SIZE), ceil(hiddenSize2/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
      update_layer<<dimGrid, dimBlock>>(
					outputSize, hiddenSize2, BATCH_SIZE,
					LEARNING_RATE,
					outputWeights, outputBiases, activationsLayer2,
					outputGradients
					);

      dimGrid = dim3(ceil(hiddenSize2/(float)BLOCK_SIZE), ceil(hiddenSize1/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
      update_layer<<dimGrid, dimBlock>>(
					hiddenSize2, hiddenSize3, BATCH_SIZE,
					LEARNING_RATE,
					hiddenWeights2, hiddenBiases2, activationsLayer1,
					hiddenGradients2
					);

      dimGrid = dim3(ceil(hiddenSize1/(float)BLOCK_SIZE), ceil(inputFeatureSize/(float)BLOCK_SIZE), 1);
      dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
      update_layer<<dimGrid, dimBlock>>(
					hiddenSize1, inputFeatureSize, BATCH_SIZE,
					LEARNING_RATE,
					hiddenWeights1, hiddenBiases1, activationsLayer1,
					hiddenGradients1
					);
#+end_src
** End of train Mini batch
#+begin_src C++
  } // end of mini batch
#+end_src
** Start of validation loop
#+begin_src C++
// We validate the model at the end of the training loop
#+end_src
** End of epoch loop
#+begin_src C++
} // end of epoch loop
#+end_src
** End main
#+begin_src C++
}
#+end_src
* Kernels
** Forward pass
:PROPERTIES:
:header-args:C++: :noeval :tangle "./kernels/fw.cu" :main no
:END:

This forward pass expects a matrix:

$$X \in \mathbb{R}^{bs \times n}$$

where bs is the batch size and n is the number of features. The weights matrix is:

$$W \in \mathbb{R}^{n \times out\_w}$$

where out_w is the number of output neurons. The biases matrix is:

$$B \in \mathbb{R}^{1 \times out\_w}$$

The output matrix is:

$$O \in \mathbb{R}^{bs \times out\_w}$$

The calculation is:

$$O = X \cdot W + B$$

#+begin_src C++
// input of (bs, n) matrix representing bs amount of samples where each sample has n dimentions.
__global__ void forward(int bs, int n, int out_w,
			float* input, float* weights, float* biases, float* out) {
  // y for rows (height of the mat)
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  // x for column (width of the mat)
  int column = blockIdx.x * blockDim.x + threadIdx.x; 

  // do the dot product between the row and col
  if (row < bs && col < out_w) {
    output[row*out_w + column] = biases[column];
    for (int i = 0; i < n; i++) {
      output[row * out_w + column] += weights[i * out_w + column] * input[row * n + i]
    }
  }
}
#+end_src

Now we need an activation function. We will use the relu function:

$$relu(x) = max(0, x)$$

#+begin_src C++

__global__ void relu(int w, int h, float* input, float* output) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < h && column < w) {
    float act = input[row * w + column];
    output[row * w + column] = act > 0.f ? act : 0.f; // relu part
  }
}
#+end_src


Finally to output the logits at the end we need softmax:

$$\text{softmax}(x) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}$$

To mitigate overflow we can substract the maxium input vector from the exponents the powers are then always negative

$$\text{softmax}(x) = \frac{e^{x_i - \max(x)}}{\sum_{j=1}^{n} e^{x_j - \max(x)}}$$

#+begin_src C++
__global__ void softmax(int w, int h, float* input, float* output) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < h && column < w) {
    float maxin = input[row * w + 0];
    for (int i = 1; i < w; i++) {
      maxin = max(maxin, input[row * w + i]);
    }
    float div = 0.f;
    for (int i = 0; i < w; i++) {
      div += exp(input[row * w + i] - maxin);
    }
    output[row * w + column] = exp(input[row * w + column] - maxin) / div;
  }
}
#+end_src

Now having the output probabilities we can calculate the loss. We will use the cross entropy loss:

$$\text{cross entropy}(y, \hat{y}) = -\sum_{i=1}^{n} y_i \log(\hat{y}_i)$$

where$$y$$is the true label and$$\hat{y}$$is the predicted label. We also use max in the y hat part to avoid log(0)

: we could use atomics but i am not sure how to implement them yet
#+begin_src C++
// gt for groud truth
// input is a matrix of batch_size x num_classes
// the kernel loops of the the number of classes per item in the batch
__global__ void cross_entropy(int w, int h, float* preds, float* gt, float* output) { 
  int idx = blockIdx.x*blockDim.x + threadIdx.x; // get the index of the current thread
  if (idx < h) {
    float loss = 0.f;
    fot (int i = 0; i < w; i++) { // loop over the number of classes
      loss -= gt[idx * w + i] * log(max(1e-6, preds[idx * w + i]));
    }
    outputs[idx] = loss;
  }
}
#+end_src

Finally for initialising the weights we can use kaiming he initialisation:

$$\text{he init}(w, h) = \sqrt{\frac{2}{w}} \cdot \text{randn}$$

where randn is a random number from a normal distribution. Not going in depth but this is done to avoid internal covariate shift.
#+begin_src C++
__global__ void he_init(int w, int h, float* weights) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < h && column < w) {
    curandState state; // State for the random number generator
    curand_init(42, row * w + column, 0, &state); // Initialize the state
    weights[row * w + column] = sqrtf(2.0 / w) * curand_normal(&state);
  }
}
#+end_src

** Backward pass
:PROPERTIES:
:header-args:C++: :noeval :tangle "./kernels/bw.cu" :main no
:END:

$$ x^n = a^{n-1}W^n+b^n $$

This means for layer n the activations of layer n-1 is equal to its inputs "x^n"

The backward pass involves gradient calculation. By applying the chain rule we can back-propagate the error. Given the loss function lets calculate the backwards cross entropy:

$$\mathcal{L} = \text{cross entropy}(y, \hat{y})$$

Lets start with the following equation with is the derivative of the loss with respect to the weights of the *last* layer:

$$\frac{\partial \mathcal{L}}{\partial w} = \frac{\partial \mathcal{L}}{\partial \hat{y}} \frac{\partial \hat{y}}{\partial w}$$

This equation says that the derivative of the loss with respect to the weights of the previous layer is the derivative of the loss with respect to the output of the last layer times the derivative of the output of the last layer with respect to the weights of the last layer. Lets start derivating!

The final activation is the softmax function. Lets derivate it:
$$\hat{y} = \text{softmax}(x) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}$$
$$\log(\hat{y}) = \log(\frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}})$$
$$\log(\hat{y}) = \log(e^{x_i}) - \log(\sum_{j=1}^{n} e^{x_j})$$
$$\log(\hat{y}) = x_i - \log(\sum_{j=1}^{n} e^{x_j})$$
Now taking the derivative actually leads to a very simple result:
$$\frac{\partial \log(\hat{y})}{\partial x_k} = \delta_{ik} - \hat{y}_k$$
$$\frac{1}{\hat{y}} \frac{\partial \log(\hat{y})}{\partial x_k} = \delta_{ik} - \hat{y}_k$$
$$\frac{\partial \hat{y}}{\partial x} = \hat{y}(1 - \hat{y})$$

The delta function is 1 if i equals k and 0 otherwise. This is the derivative of the softmax function.

Then we applied a cross entropy loss function. Lets derivate it:
$$\mathcal{L} = -\sum_{i=1}^{n} y_i \log(\hat{y}_i)$$
$$\frac{\partial \mathcal{L}}{\partial \hat{y}} = -\frac{y}{\hat{y}}$$

Now we can use the product of these two to find the full derivative:
TODO ( I just realised its not w is x )
$$\frac{\partial \mathcal{L}}{\partial w} = \frac{\partial \mathcal{L}}{\partial \hat{y}} \frac{\partial \hat{y}}{\partial w}$$
$$\frac{\partial \mathcal{L}}{\partial w} = -\frac{y}{\hat{y}} \times \hat{y}(1 - \hat{y}) $$ - I am not sure if this is the derivation (double check when possible)
$$\frac{\partial \mathcal{L}}{\partial w} = \hat{y} - y $$ - I do know this is the final


So this is the backwards for the cross entropy:
#+begin_src C++
__global__ void ce_back(int w, int h, float* preds, float* gt, float* output) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  // x for column (width of the mat)
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < h && column < w) {
    // $$\frac{\partial \mathcal{L}}{\partial w} = \hat{y} - y $$

    output[row * w + column] = preds[row * w + column] - gt[row * w + column]
   }
}
#+end_src


With the derivate of the loss with respect to the inputs of the output layer: (in here y hat is the activation's of last layer, but from now on i will refer to activation's as a)
$$\frac{\partial \mathcal{L}}{\partial x^n} = \frac{\partial \mathcal{L}}{\partial \hat{y}^n}\frac{\partial \hat{y}^n}{\partial x^n}$$
We must take a step backwards to layer n-1:
$$\frac{\partial \mathcal{L}}{\partial a^{n-1}} = \frac{\partial \mathcal{L}}{\partial \hat{y}^n}\frac{\partial \hat{y}^n}{\partial x^n} \times \frac{\partial x^n}{\partial a^{n-1}}$$

So the values $x^n$: refer to this
$$ x^n = a^{n-1}W^n+b^n $$
$$ \frac{\partial x^n}{\partial a^{n-1}} = W^n $$

We must matrix multiply to backprop. Once we have the derivative of x^n with respect to the loss at the last layer we can go back:
$$ \frac{\partial \mathcal{L}}{\partial x^{n-1}} = \frac{\partial \mathcal{L}}{\partial x^{n}} \frac{\partial x^n}{\partial a^{n-1}} $$
$$ \frac{\partial \mathcal{L}}{\partial x^{n-1}} = \frac{\partial \mathcal{L}}{\partial x^{n}} W^n $$

#+begin_src C++
__global__ void backward(int bs, int n, int out_w, float* weights, float* biases, float* d_l, float* out_d_l) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < bs && column < n) {
    float dl = 0.f;
    // $$ \frac{\partial \mathcal{L}}{\partial x^{n-1}} = \frac{\partial \mathcal{L}}{\partial x^{n}} W^n $$
    // in english our weights times the derivative of the next layer so n + 1
    for (int i = 0; i < n; i++) {
      float w = weights[i * out_w + column];
      dl += w * d_l[row * n + i];
    }
    out_d_l[row * out_w + column] = dl;
  }
}
#+end_src


Finally we need the backprop relu:
#+begin_src C++
__global__ void relu_bw(int w, int h, int ns, float* a, float* d_l, float* b) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < bs && column < n) {
    float act = a[row * w + column];
    b[row * w + column] = act > 0.f ? d_l[row * w + column] : 0.f;
  }
}
#+end_src

With this we are just left to calculate the derivative of the loss with respect to the weights:
$$ x^n = a^{n-1}W^n+b^n $$
$$ \frac{\partial x^n}{\partial W^n} = a^{n-1} $$
$$ \frac{\partial x^n}{\partial b^n} = 1 $$

And we can update our weights and biases as follows:
$$ w \leftarrow w - \frac{\eta}{bs}\frac{\partial L}{\partial w^n} $$
$$ b \leftarrow b - \frac{\eta}{bs}\frac{\partial L}{\partial b^n} $$

#+begin_src C++
__global__ update_layer(int w, int h, int bs, float lr, float* weights, float* biases, float* activations, float* d_l) {
  int row = blockIdx.y * blockDim.y + threadIdx.y; 
  int column = blockIdx.x * blockDim.x + threadIdx.x; 
  if (row < bs && column < n) {
    float dw = 0.f;
    float db = 0.f;
    for (int i = 0; i < bs ; i++) {
      float act = activations[i * h + row];
      float dl = d_l[i * w + column];
      dw += act * dl;
      db += dl;
    }
    weights[row * w + column] -= lr * dw / bs;
    biases[column] -= lr * db / bs;
  }
}
#+end_src

* Helpers
Curtesy of Oz
#+begin_src C++ :tangle "src/helpers.cpp"
void print_matrix(int w, int h, float* matrix, std::string title)
{
  float* m_h = new float[w*h];
  cudaMemcpy(m_h, matrix, w*h*sizeof(float), cudaMemcpyDeviceToHost);
  std::cout<<title<<std::endl;
  for(int i = 0; i<h; i++)
  {
    for(int j = 0; j<w; j++)
    {
      std::cout<<std::fixed<<std::setprecision(3)<<m_h[i*w+j]<<", ";
    }
    std::cout<<std::endl;
  }
  free(m_h);
}

void initLayer(float* weights, float* biases, int w, int h, int BLOCK_SIZE)
{
  dim3 dimGrid = dim3(ceil(w/(float)BLOCK_SIZE), ceil(h/(float)BLOCK_SIZE), 1);
  dim3 dimBlock = dim3(BLOCK_SIZE, BLOCK_SIZE, 1);
  init_rand<<<dimGrid, dimBlock>>>(w, h, weights);
  gpuErrchk(cudaPeekAtLastError());

  dimGrid = dim3(ceil(h/(float)BLOCK_SIZE), 1, 1);
  dimBlock = dim3(BLOCK_SIZE, 1, 1);
  init_rand<<<dimGrid, dimBlock>>>(1, h, biases);
  gpuErrchk(cudaPeekAtLastError());
}

void read_mnist(const std::string filename, int length, float* x, float* y)
{
  int input_size = 784;
  int labels = 10;

  std::fstream fin;
  fin.open(filename);
  std::string row;
  constexpr char delim = ',';
  for(int i = 0; i<length; i++)
  {
    fin >> row;
    int pos = row.find(delim);
    int label = std::stoi(row.substr(0, pos+1));
    for(int j = 0; j<labels; j++)
    {
      y[labels*i + j] = (j==label);
    }
    row.erase(0, pos+1);
    for(int j = 0; j<input_size; j++)
    {
      pos = row.find(delim);
      if (pos == std::string::npos)
      {
        pos = row.length() - 1;
      }
      x[i*input_size+j] = std::stof(row.substr(0, pos+1)) / 255; //normalize value
      row.erase(0, pos+1);
    }
    ASSERT(row.length() == 0, "didn't parse all values in row, %d", i);
  }
}
#+end_src
